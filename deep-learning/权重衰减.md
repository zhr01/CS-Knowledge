# 权重衰减

L1和L2的定义：
$$
C_2 = C_0 + \frac{\lambda}{2n}\sum_w W^2 \\
C_1 = C_0 + \frac{\lambda}{n}\sum_w |W|^2
$$
其中C0为未加上惩罚项的代价函数。



### 为什么正则化能够减小权值

加上正则项后损耗函数对权重的偏导变为：
$$
\frac{\partial C2}{\partial W} = \frac{\partial C_0}{\partial W} + \frac{\lambda}{n}W
$$
相应的权重学习规则变为：
$$
W\rightarrow W- \eta(\frac{\partial C_0}{\partial W} + \frac{\lambda}{n}W) = (1-\frac{\eta \lambda}{n})W - \eta \frac{\partial C_0}{\partial W}
$$
这里权重W乘以一个$ (1-\frac{\eta \lambda}{n})$因子，这就是权重下降的原因。

同样的对于L1正则化也有相对结论。



### 为什么较小的权重能防止过拟合

过拟合的特点是对非本质特征的噪声过于敏感，把训练样本里的噪声当作了特征。通过正则化，权值小对小的噪声干扰产生的加权和相差就比较小，从而不会改变激活函数的值，具备了对噪声的抗干扰能力。

















