## 间隔与支持向量

给定训练样本集$D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\},y_i \in \{-1,+1\}$，分类学习最基本的想法就是找到一个超平面将不同类别的样本分开。如下图所示

![](pic/svm.png)

划分超平面可用如下线性方程来描述：
$$
\mathbf{w}^T \mathbf{x}+b = 0 \tag{1}
$$
其中$\mathbf{w}=(w_1;w_2;...;w_d)$为法向量，决定超平面的方向；b为位移项，决定超平面与原点间的距离。样本空间的任意点到超平面的距离可写为：
$$
r = \frac{|\mathbf{W}^T\mathbf{x}+b|}{||\mathbf{W}||} \tag{2}
$$
假设超平面$(\mathbf{w},b)$能将训练样本正确分类，即对于$(\mathbf{x_i},y_i) \in D$，若$y_i=+1$，则有$\mathbf{w}^T \mathbf{x}+b >0$；若$y_i=-1$，则有$\mathbf{w}^T \mathbf{x}+b <0$。令：

$$
\cases{\mathbf{w}^T \mathbf{x_i}+b \geq +1 , & y_i=+1 \\
\mathbf{w}^T \mathbf{x_i}+b \leq -1 , & y_i= - 1 } \tag{3}
$$
如下图所示，距离超平面最近的几个**样本点**使（3）的等号成立，称之为**支持向量**，根据（2）式，两个异类支持向量到超平面的距离之和为：
$$
\gamma = \frac{2}{\mathbf{||W||}} \tag{4}
$$
该距离值称之为“间隔(margin)”。显然，为了最大化间隔，找到满足（3）式约束参数W和b的基础上，仅需最小化$||\mathbf{W}||^2$，得支持向量机基本型：
$$
min_{w,b}\ \frac{1}{2}||w||^2 \\
\mathop{s.t.}\ y_i(\mathbf{w^T}\mathbf{x_i}+b) \geqslant 1,\ \ i=1,2,...,m. \tag{5}
$$


![](pic/svm2.png)



- 这个最优化问题被称作原问题。我们不会直接解它，而是把它转化为对偶问题进行解决。
- 为了使问题变得易于处理，我们的方法是把目标函数和约束全部融入一个新的函数，即拉格朗日函数，再通过这个函数来寻找最优点。

将（5）式转化为拉格朗日对偶问题，然后对W和b求导，有导函数为零，得对偶问题为：
$$
\mathop{max}_{\alpha}\ \sum_{i=1}^m \alpha_i-\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i\alpha_jy_iy_j\mathbf{x_i}^T\mathbf{x_j} \\
s.t.\ \sum_{i=1}^m\alpha_iy_i=0, \ \alpha_i>0,\ i=1,2,...,m \tag{6}
$$
可通过SMO求解上式。



### 核函数

前面讨论中假定样本线性可分的，然而实际任务中，原始样本空间也许并不存在能正确划分两类样本的超平面，对于这样的问题，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间中线性可分。

令$\phi (x)$表示将x映射后的特征向量，于是划分超平面所对应的模型变为：
$$
f(x) = W^T\phi(x)+b
$$
支持向量机的原问题变为：
$$
min_{w,b}\ \frac{1}{2}||w||^2 \\\mathop{s.t.}\ y_i(\mathbf{w^T}\mathbf{\phi(x_i)}+b) \geqslant 1,\ \ i=1,2,...,m.
$$
其对偶问题为：
$$
\mathop{max}_{\alpha}\ \sum_{i=1}^m \alpha_i-\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i\alpha_jy_iy_j\mathbf{\phi(x_i)}^T\mathbf{\phi(x_j)} \\
s.t.\ \sum_{i=1}^m\alpha_iy_i=0, \ \alpha_i>0,\ i=1,2,...,m \tag{7}
$$
由于$\phi(x_i)^T\phi(x_j) $求解较为困难，因此设想一个函数使得：
$$
\kappa(x_i, x_j) =\langle \phi(x_i), \phi(x_j)\rangle = \phi(x_i)^T\phi(x_j)
$$
即$x_i$与$x_j$在特征空间的内积等于它们在原始样本空间中通过函数$\kappa(\cdot,\cdot)$计算的结果。这里的函数$\kappa(\cdot,\cdot)$就称为核函数。常用的核函数有：

![](pic/kernel.jpg)



### 软间隔与正则化

在现实任务中，难以确定合适的核函数使训练集在特征空间中线性可分，即使找到核函数也难以断定线性可分不是过拟合造成的结果。之前的SVM要求所有的样本均满足约束（3），这称为“硬间隔”。为了解决以上问题，允许SVM在一些样本上出错，即“软间隔”，如下图所示：

![](pic/soft_margin.jpg)





补充：

- 凸优化

  “凸优化”是指一种比较特殊的优化，是指求取最小值的目标函数为凸函数的一类优化问题。其中，目标函数为凸函数且定义域为凸集的优化问题称为无约束凸优化问题。而目标函数和不等式约束函数均为凸函数，等式约束函数为仿射函数，并且定义域为凸集的优化问题为约束优化问题

- 拉格朗日对偶函数

- 强对偶性